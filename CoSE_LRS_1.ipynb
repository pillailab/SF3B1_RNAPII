{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nDetermining CoSE from files generated by bedtools\\nPlease look at project/Knowledgebase/Notes for additional files\\nThe only difference from CoSE_1 is that this uses all introns and CoSE_1 uses first intron\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Determining CoSE from LRS\n",
    "Intermediate files generated by bedtools\n",
    "Uses modules installed by conda\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load modules\n",
    "\n",
    "import os\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.api.types import CategoricalDtype\n",
    "import mygene\n",
    "import scipy\n",
    "\n",
    "from plotnine import *\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.rcParams['pdf.fonttype'] = 42 # export pdfs with editable font types in Illustrator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of Junctions with overlap of 10 bp on each side. Generated by bedtools\n",
    "# path to files to be changed by user\n",
    "\n",
    "Jn_list = ['/home/mp758/scratch60/SF3B1_PRC2_1/SF3B1_LRS/porechop/CoSE/MUT3.alljns.intron.overlap.plus10.txt',\n",
    "           '/home/mp758/scratch60/SF3B1_PRC2_1/SF3B1_LRS/porechop/CoSE/MUT2.alljns.intron.overlap.plus10.txt',\n",
    "           '/home/mp758/scratch60/SF3B1_PRC2_1/SF3B1_LRS/porechop/CoSE/WT1.alljns.intron.overlap.plus10.txt', \n",
    "           '/home/mp758/scratch60/SF3B1_PRC2_1/SF3B1_LRS/porechop/CoSE/WT2.alljns.intron.overlap.plus10.txt'\n",
    "          ]\n",
    "           \n",
    "           \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate Junction overlaps\n",
    "def make_Jn_overlap(jn):\n",
    "    namea, nameb = os.path.split(jn)\n",
    "    namec = nameb.split(\"_\")[0]\n",
    "    # read junction files\n",
    "    SJ1=pd.read_csv(jn,\n",
    "                sep = \"\\t\",\n",
    "                delimiter = '\\t', index_col = False,\n",
    "                      names =  ['chr_a', 'start_a', 'end_a', 'name_a', 'score_a', 'strand_a','chr_b', 'start_b', 'end_b', 'name_b', 'score_b', 'strand_b',\"overlap\",\"span_a\",\"span_b\", \"diff_span\" ]\n",
    "                   )\n",
    "    jn[\"chr_name\"] = jn['chr_a']+\"_\"+jn['start_a'].apply(str)+\"_\"+jn['end_a'].apply(str)+\"_\"+jn['strand_a'] # new column chr_name\n",
    "    SJ1.loc[SJ1['strand_'] == 1, 'strand'] = \"+\"\n",
    "    SJ1.loc[SJ1['strand_'] == 2, 'strand'] = \"-\"\n",
    "    SJ1['name']=SJ1['chr']+\"_\"+SJ1['start'].astype(str)+\"_\"+SJ1['end'].astype(str)+\"_\"+SJ1['strand'] # new column name \n",
    "    SJ1['score']= SJ1['unique']+SJ1['multi_map'] # both single and multimapping reads included\n",
    "    SJ1=SJ1[SJ1['annotated'] == 1] # only annotated reads included\n",
    "    SJ1=SJ1.dropna() # those with any NA are dropped\n",
    "    SJ1=SJ1[['chr', 'start', 'end','name','score','strand']] # reduce file to just standard bed6 format\n",
    "    folder1='/home/mp758/scratch60/SF3B1_PRC2_1/SF3B1_FastGro/Splice_Junctions'\n",
    "    path1=folder1+'/'+namec+\".STAR_Jn.bed\" # new folder for all splice junctions\n",
    "    # write splice junctions to files\n",
    "    SJ1.to_csv(path1,\n",
    "            sep = \"\\t\",\n",
    "             header = None,\n",
    "             index = False)\n",
    "    \n",
    "    print(namea, nameb, namec)\n",
    "    #print(SJ1.head)\n",
    "    "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "### Bedtools and processing of bedfiles for intersection. All done in terminal or slurm jobs\n",
    "\n",
    "gtf from NCBI\n",
    "\n",
    "# grep NM from Chiazzi paper for major transcripts\n",
    "\n",
    "tail -n+4 GSE148433_human.refseq.major.TR.gtf | awk -F\"\\t\" '{print$9}' | awk -F\";\" '{print $2}' | awk '{print $2}' | sed 's/.$//; s/^.//' > NM_list.txt\n",
    "\n",
    "# convert gtf to bed, or directly download from ucsc table \n",
    "# convert LRS to bam with \n",
    "bedtools bamtobed -i .bam, or directly use bam files after alignment with minimap2\n",
    "\n",
    "# Extract Junction files using biocondcutor-deseq2 conda Rsamtools\n",
    "# Follow instructions in Tools/R/Rsamtools-GenomicAlignments\n",
    "# Obtain junctions.df\n",
    "Then get to bed of the junctions using the below:\n",
    "\n",
    "awk '(NR>1) {print $3\"\\t\"$4\"\\t\"$5\"\\t\"$2\"\\t\"\".\"\"\\t\"$7}' WT1.LRS.Junctions.df > WT1.LRS.Junctions.bed\n",
    "\n",
    "# Combined the bed files to make one master junctions file.\n",
    "# Possibly can also be done by combining bamfiles upfront.\n",
    "\n",
    "cat  bed1 bed2.... | sort -k1,1 -k2,2n | awk '{ print $1\"\\t\"$2\"\\t\"$3\"\\t\"\"LRS\"\"\\t\"$5\"\\t\"$6}'| uniq > combined.Junctions.bed\n",
    "# make 10 bp on each side to accommodate for slight misreads\n",
    "awk '{ print $1\"\\t\"$2-10\"\\t\"$3+10\"\\t\"$4\"\\t\"$5\"\\t\"$6}' combined.Junctions.bed > combined.Junctions.plus10.bed\n",
    "\n",
    "# first intesect intron.bed with combinedWT-MUT.bed\n",
    "# this will create the list of introns with atleast SOME overlap with the WT-MUT.bed\n",
    "# probably unnecesary overall\n",
    "\n",
    "bedtools intersect -a K562_major.intronp+1.unique.bed -b WT1-MUT1_combined.Junctions.bed -u > intron.overlap.combined.bed\n",
    "\n",
    "# Step 1 - get precise spliced junctions.\n",
    "# Using awk for this to limit to junctions no more than 10 basepairs from either side of the first.intron.overlap**.bed\n",
    "# the -b bed files are the respective junction files (extraded from junctions.df)\n",
    "\n",
    "bedtools intersect -a intron.overlap.combined.bed -b junction.bed -wao -s | awk '$13!=0 {print $0\"\\t\"$3-$2\"\\t\"$9-$8}'| awk 'sqrt(($2-$8)*($2-$8)) < 10 && sqrt(($3-$9)*($3-$9)) <10 {print $0\"\\t\"$14-$15}' > WT2.intron.overlap.plus10.txt\n",
    "\n",
    "# Step 2 - get total number of reads spanning the junctions\n",
    "# get overlaps with numbers. Needs to get ALL overlaps to combine the WT and MUT files for ratios\n",
    "# this is the file for downstream calculation in this notebooke\n",
    "###\n",
    "bedtools intersect -a first.intron.overlap.WT-MUT.bed -b WT2.bed6.bed -wao -s | awk '$13!=0 {print $0}' | awk '{if ($6==\"+\" && $2>=$8 && $9-$3 >35) print $0; else if ($6==\"-\" && $9>=$3 && $2-$8>35) print $0}' > WT2.first-intron.overlap.txt \n",
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make intron overlap list generated above\n",
    "\n",
    "intron_list = [\n",
    "    '/home/mp758/scratch60/SF3B1_PRC2_1/SF3B1_LRS/porechop/CoSE/WT1.all-intron.overlap.txt',\n",
    "    '/home/mp758/scratch60/SF3B1_PRC2_1/SF3B1_LRS/porechop/CoSE/WT2.all-intron.overlap.txt',\n",
    "    '/home/mp758/scratch60/SF3B1_PRC2_1/SF3B1_LRS/porechop/CoSE/MUT2.all-intron.overlap.txt',\n",
    "    '/home/mp758/scratch60/SF3B1_PRC2_1/SF3B1_LRS/porechop/CoSE/MUT3.all-intron.overlap.txt'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only intron name. Please note difference with the next function intron_overlap2\n",
    "\n",
    "def intron_overlap(intron):\n",
    "    namea, nameb = os.path.split(intron)\n",
    "    namec = nameb.split(\".\")[0]\n",
    "    named = nameb.split(\".\")[1]\n",
    "    intron1 = pd.read_csv(intron, \n",
    "                      delimiter = '\\t', \n",
    "                          index_col = False,\n",
    "                      names =  ['chr_a', 'start_a', 'end_a', 'name_a', 'score_a', 'strand_a','chr_b', 'start_b', 'end_b', 'name_b', 'score_b', 'strand_b',\"overlap\" ])\n",
    "    \n",
    "    # passing function\n",
    "    agg_func_math = {\n",
    "        'name_a':\n",
    "        ['count']\n",
    "            }\n",
    "    intron_count = intron1.groupby(['name_a']).agg(agg_func_math).round(2)\n",
    "    intron_count.columns = intron_count.columns.to_flat_index().str.join('_')\n",
    "    intron_count['name_a'] = intron_count.index\n",
    "    intron_count.index = np.arange(len(intron_count))\n",
    "    intron_count_over10 = intron_count[intron_count['name_a_count'] > 10]\n",
    "    intron_count.columns = ['intron_count', 'name_a']\n",
    "\n",
    "    \n",
    "    folder1 = '/home/mp758/scratch60/SF3B1_PRC2_1/SF3B1_LRS/porechop/CoSE'\n",
    "    jn  = folder1+'/'+namec+'.alljns.intron.overlap.plus10.txt'\n",
    "    jn1 = pd.read_csv(jn,\n",
    "                delimiter = '\\t', \n",
    "                      index_col = False,\n",
    "                      names =  ['chr_a', 'start_a', 'end_a', 'name_a', 'score_a', 'strand_a','chr_b', 'start_b', 'end_b', 'name_b', 'score_b', 'strand_b',\"overlap\",\"span_a\",\"span_b\", \"diff_span\" ]\n",
    "                     )\n",
    "    jn1[\"chr_name\"] = jn1['chr_a']+\"_\"+jn1['start_a'].apply(str)+\"_\"+jn1['end_a'].apply(str)+\"_\"+jn1['strand_a']\n",
    "    jn1_count = jn1.groupby(['name_a']).agg(agg_func_math).round(2)\n",
    "    \n",
    "    jn1_count.columns = jn1_count.columns.to_flat_index().str.join('_')\n",
    "    jn1_count['name_a'] = jn1_count.index\n",
    "    jn1_count.index = np.arange(len(jn1_count))\n",
    "    \n",
    "\n",
    "    jn1_count.columns = ['jn_count', 'name_a']\n",
    "    merged1 = pd.merge(intron_count, jn1_count, on = 'name_a', how = \"left\")\n",
    "\n",
    "    merged1 = merged1.fillna(0).round(2)\n",
    "    merged1['CoSE'] = (merged1['jn_count']/merged1['intron_count']).round(2)\n",
    "    merged1['sample'] = namec\n",
    "    merged1 = merged1[merged1[\"jn_count\"]>1]\n",
    "    #merged1.columns = \n",
    "    dest = folder1+'/'+'Final'+'/'+namec+'.'+named+'.CoSE.txt'\n",
    "    merged1.to_csv(dest, sep = '\\t', index = False, header = True) \n",
    "    \n",
    "    print(namea, nameb, namec)\n",
    "    print(intron_count.head(5))\n",
    "    #print(intron_count_over10.head(5))\n",
    "    print(jn1_count.head(10))\n",
    "    print(merged1.head(5))\n",
    "    #print(intron_count.columns)\n",
    "    #print(intron_count_over10.counts)\n",
    "    print(jn1_count.columns)\n",
    "    print(merged1.columns)\n",
    "    print(dest)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for intron in intron_list:\n",
    "    intron_overlap(intron)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
