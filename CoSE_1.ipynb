{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nDetermining CoSE from files generated by bedtools\\nPlease look at project/Knowledgebase/Notes for additional files\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Determining CoSE from files generated by bedtools\n",
    "Please look at project/Knowledgebase/Notes for additional files\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'mygene'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtypes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CategoricalDtype\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmygene\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mplotnine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'mygene'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.api.types import CategoricalDtype\n",
    "import mygene\n",
    "import scipy\n",
    "\n",
    "from plotnine import *\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.rcParams['pdf.fonttype'] = 42 # export pdfs with editable font types in Illustrator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/gpfs/ysm/project/pillai/mp758/Tools/Jupyter_Notebooks/Reimer_2021/MEL_LRS/data_analysis'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make dataframe from \n",
    "MUT3_jn = pd.read_csv('/home/mp758/scratch60/SF3B1_PRC2_1/SF3B1_LRS/porechop/CoSE/MUT3.jn.overlap.plus10.txt', \n",
    "                      delimiter = '\\t', index_col = False,\n",
    "                      names =  ['chr_a', 'start_a', 'end_a', 'name_a', 'score_a', 'strand_a','chr_b', 'start_b', 'end_b', 'name_b', 'score_b', 'strand_b',\"overlap\",\"span_a\",\"span_b\", \"diff_span\" ])\n",
    "\n",
    "MUT3_jn[\"chr_name\"]=MUT3_jn['chr_a']+\"_\"+MUT3_jn['start_a'].apply(str)+\"_\"+MUT3_jn['end_a'].apply(str)+\"_\"+MUT3_jn['strand_a']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make dataframe from \n",
    "MUT2_jn = pd.read_csv('/home/mp758/scratch60/SF3B1_PRC2_1/SF3B1_LRS/porechop/CoSE/MUT2.jn.overlap.plus10.txt', \n",
    "                      delimiter = '\\t', index_col = False,\n",
    "                      names =  ['chr_a', 'start_a', 'end_a', 'name_a', 'score_a', 'strand_a','chr_b', 'start_b', 'end_b', 'name_b', 'score_b', 'strand_b',\"overlap\",\"span_a\",\"span_b\", \"diff_span\" ])\n",
    "\n",
    "MUT2_jn[\"chr_name\"]=MUT2_jn['chr_a']+\"_\"+MUT2_jn['start_a'].apply(str)+\"_\"+MUT2_jn['end_a'].apply(str)+\"_\"+MUT2_jn['strand_a']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make dataframe from \n",
    "WT1_jn = pd.read_csv('/home/mp758/scratch60/SF3B1_PRC2_1/SF3B1_LRS/porechop/CoSE/WT1.jn.overlap.plus10.txt', \n",
    "                      delimiter = '\\t', index_col = False,\n",
    "                      names =  ['chr_a', 'start_a', 'end_a', 'name_a', 'score_a', 'strand_a','chr_b', 'start_b', 'end_b', 'name_b', 'score_b', 'strand_b',\"overlap\",\"span_a\",\"span_b\", \"diff_span\" ])\n",
    "\n",
    "WT1_jn[\"chr_name\"]=WT1_jn['chr_a']+\"_\"+WT1_jn['start_a'].apply(str)+\"_\"+WT1_jn['end_a'].apply(str)+\"_\"+WT1_jn['strand_a']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make dataframe from \n",
    "WT2_jn = pd.read_csv('/home/mp758/scratch60/SF3B1_PRC2_1/SF3B1_LRS/porechop/CoSE/WT2.jn.overlap.plus10.txt', \n",
    "                      delimiter = '\\t', index_col = False,\n",
    "                      names =  ['chr_a', 'start_a', 'end_a', 'name_a', 'score_a', 'strand_a','chr_b', 'start_b', 'end_b', 'name_b', 'score_b', 'strand_b',\"overlap\",\"span_a\",\"span_b\", \"diff_span\" ])\n",
    "\n",
    "WT2_jn[\"chr_name\"]=WT2_jn['chr_a']+\"_\"+WT2_jn['start_a'].apply(str)+\"_\"+WT2_jn['end_a'].apply(str)+\"_\"+WT2_jn['strand_a']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "MUT3_intron = pd.read_csv('/home/mp758/scratch60/SF3B1_PRC2_1/SF3B1_LRS/porechop/CoSE/MUT3.first-intron.overlap.txt', \n",
    "                      delimiter = '\\t', index_col = False,\n",
    "                      names =  ['chr_a', 'start_a', 'end_a', 'name_a', 'score_a', 'strand_a','chr_b', 'start_b', 'end_b', 'name_b', 'score_b', 'strand_b',\"overlap\" ])\n",
    "\n",
    "MUT3_intron[\"chr_name\"]=MUT3_intron['chr_a']+\"_\"+MUT3_intron['start_a'].apply(str)+\"_\"+MUT3_intron['end_a'].apply(str)+\"_\"+MUT3_intron['strand_a']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "MUT2_intron = pd.read_csv('/home/mp758/scratch60/SF3B1_PRC2_1/SF3B1_LRS/porechop/CoSE/MUT2.first-intron.overlap.txt', \n",
    "                      delimiter = '\\t', index_col = False,\n",
    "                      names =  ['chr_a', 'start_a', 'end_a', 'name_a', 'score_a', 'strand_a','chr_b', 'start_b', 'end_b', 'name_b', 'score_b', 'strand_b',\"overlap\" ])\n",
    "\n",
    "MUT2_intron[\"chr_name\"]=MUT2_intron['chr_a']+\"_\"+MUT2_intron['start_a'].apply(str)+\"_\"+MUT2_intron['end_a'].apply(str)+\"_\"+MUT2_intron['strand_a']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "WT1_intron = pd.read_csv('/home/mp758/scratch60/SF3B1_PRC2_1/SF3B1_LRS/porechop/CoSE/WT1.first-intron.overlap.txt', \n",
    "                      delimiter = '\\t', index_col = False,\n",
    "                      names =  ['chr_a', 'start_a', 'end_a', 'name_a', 'score_a', 'strand_a','chr_b', 'start_b', 'end_b', 'name_b', 'score_b', 'strand_b',\"overlap\" ])\n",
    "\n",
    "WT1_intron[\"chr_name\"]=WT1_intron['chr_a']+\"_\"+WT1_intron['start_a'].apply(str)+\"_\"+WT1_intron['end_a'].apply(str)+\"_\"+WT1_intron['strand_a']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "WT2_intron = pd.read_csv('/home/mp758/scratch60/SF3B1_PRC2_1/SF3B1_LRS/porechop/CoSE/WT2.first-intron.overlap.txt', \n",
    "                      delimiter = '\\t', index_col = False,\n",
    "                      names =  ['chr_a', 'start_a', 'end_a', 'name_a', 'score_a', 'strand_a','chr_b', 'start_b', 'end_b', 'name_b', 'score_b', 'strand_b',\"overlap\" ])\n",
    "\n",
    "WT2_intron[\"chr_name\"]=WT2_intron['chr_a']+\"_\"+WT2_intron['start_a'].apply(str)+\"_\"+WT2_intron['end_a'].apply(str)+\"_\"+WT2_intron['strand_a']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "WT_jn = pd.concat([WT1_jn, WT2_jn])\n",
    "WT_intron = pd.concat([WT1_intron, WT2_intron])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "MUT_jn = pd.concat([MUT2_jn, MUT3_jn])\n",
    "MUT_intron = pd.concat([MUT2_intron, MUT3_intron])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# passing fun\n",
    "#agg_func_math = {'ratio':['mean', 'median', 'min', 'max', 'std', 'var', 'count']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# passing fun\n",
    "agg_func_math = {\n",
    "    'name_a':\n",
    "    ['count']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "MUT3_jn_count = MUT3_jn.groupby(['name_a']).agg(agg_func_math).round(2)\n",
    "MUT2_jn_count = MUT2_jn.groupby(['name_a']).agg(agg_func_math).round(2)\n",
    "\n",
    "WT1_jn_count = WT1_jn.groupby(['name_a']).agg(agg_func_math).round(2)\n",
    "WT2_jn_count = WT2_jn.groupby(['name_a']).agg(agg_func_math).round(2)\n",
    "#MUT3_3prime_position.columns = ['mean', 'median', 'min', 'max', 'std', 'var', 'count']\n",
    "\n",
    "#MUT3_3prime_position = MUT3_3prime_position[MUT3_3prime_position['count'] > 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "MUT2_jn_count.columns = MUT2_jn_count.columns.to_flat_index().str.join('_')\n",
    "MUT2_jn_count['name_a'] = MUT2_jn_count.index\n",
    "MUT2_jn_count.index = np.arange(len(MUT2_jn_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "MUT3_jn_count.columns = MUT3_jn_count.columns.to_flat_index().str.join('_')\n",
    "MUT3_jn_count['name_a'] = MUT3_jn_count.index\n",
    "MUT3_jn_count.index = np.arange(len(MUT3_jn_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "WT1_jn_count.columns = WT1_jn_count.columns.to_flat_index().str.join('_')\n",
    "WT1_jn_count['name_a'] = WT1_jn_count.index\n",
    "WT1_jn_count.index = np.arange(len(WT1_jn_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "WT2_jn_count.columns = WT2_jn_count.columns.to_flat_index().str.join('_')\n",
    "WT2_jn_count['name_a'] = WT2_jn_count.index\n",
    "WT2_jn_count.index = np.arange(len(WT2_jn_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "MUT3_intron_count = MUT3_intron.groupby(['name_a']).agg(agg_func_math).round(2)\n",
    "MUT2_intron_count = MUT2_intron.groupby(['name_a']).agg(agg_func_math).round(2)\n",
    "\n",
    "WT1_intron_count = WT1_intron.groupby(['name_a']).agg(agg_func_math).round(2)\n",
    "WT2_intron_count = WT2_intron.groupby(['name_a']).agg(agg_func_math).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "MUT2_intron_count.columns = MUT2_intron_count.columns.to_flat_index().str.join('_')\n",
    "MUT2_intron_count['name_a'] = MUT2_intron_count.index\n",
    "MUT2_intron_count.index = np.arange(len(MUT2_intron_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "MUT3_intron_count.columns = MUT3_intron_count.columns.to_flat_index().str.join('_')\n",
    "MUT3_intron_count['name_a'] = MUT3_intron_count.index\n",
    "MUT3_intron_count.index = np.arange(len(MUT3_intron_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "WT1_intron_count.columns = WT1_intron_count.columns.to_flat_index().str.join('_')\n",
    "WT1_intron_count['name_a'] = WT1_intron_count.index\n",
    "WT1_intron_count.index = np.arange(len(WT1_intron_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "WT2_intron_count.columns = WT2_intron_count.columns.to_flat_index().str.join('_')\n",
    "WT2_intron_count['name_a'] = WT2_intron_count.index\n",
    "WT2_intron_count.index = np.arange(len(WT2_intron_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "MUT2_intron_count_over5 = MUT2_intron_count[MUT2_intron_count['name_a_count'] > 5]\n",
    "MUT3_intron_count_over5 = MUT3_intron_count[MUT3_intron_count['name_a_count'] > 5]\n",
    "\n",
    "WT1_intron_count_over5 = WT1_intron_count[WT1_intron_count['name_a_count'] > 5]\n",
    "WT2_intron_count_over5 = WT2_intron_count[WT2_intron_count['name_a_count'] > 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "MUT_jn_count = MUT_jn.groupby(['name_a']).agg(agg_func_math).round(2)\n",
    "WT_jn_count = WT_jn.groupby(['name_a']).agg(agg_func_math).round(2)\n",
    "\n",
    "MUT_jn_count.columns = MUT_jn_count.columns.to_flat_index().str.join('_')\n",
    "MUT_jn_count['name_a'] = MUT_jn_count.index\n",
    "MUT_jn_count.index = np.arange(len(MUT_jn_count))\n",
    "\n",
    "WT_jn_count.columns = WT_jn_count.columns.to_flat_index().str.join('_')\n",
    "WT_jn_count['name_a'] = WT_jn_count.index\n",
    "WT_jn_count.index = np.arange(len(WT_jn_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "MUT_intron_count = MUT_intron.groupby(['name_a']).agg(agg_func_math).round(2)\n",
    "WT_intron_count = WT_intron.groupby(['name_a']).agg(agg_func_math).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "MUT_intron_count.columns = MUT_intron_count.columns.to_flat_index().str.join('_')\n",
    "MUT_intron_count['name_a'] = MUT_intron_count.index\n",
    "MUT_intron_count.index = np.arange(len(MUT_intron_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "WT_intron_count.columns = WT_intron_count.columns.to_flat_index().str.join('_')\n",
    "WT_intron_count['name_a'] = WT_intron_count.index\n",
    "WT_intron_count.index = np.arange(len(WT_intron_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "MUT_intron_count_over5 = MUT_intron_count[MUT_intron_count['name_a_count'] > 5]\n",
    "\n",
    "WT_intron_count_over5 = WT_intron_count[WT_intron_count['name_a_count'] > 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "MUT2_jn_count.columns = ['jn_count', 'name_a']\n",
    "MUT2_merged = pd.merge(MUT2_intron_count_over5, MUT2_jn_count, on = 'name_a', how = \"left\")\n",
    "\n",
    "MUT2_merged = MUT2_merged.fillna(0).round(2)\n",
    "MUT2_merged['CoSE'] = (MUT2_merged['jn_count']/MUT2_merged['name_a_count']).round(2)\n",
    "MUT2_merged['sample'] = 'MUT2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "MUT3_jn_count.columns = ['jn_count', 'name_a']\n",
    "MUT3_merged = pd.merge(MUT3_intron_count_over5, MUT3_jn_count, on = 'name_a', how = \"left\")\n",
    "\n",
    "MUT3_merged = MUT3_merged.fillna(0).round(2)\n",
    "MUT3_merged['CoSE'] = (MUT3_merged['jn_count']/MUT3_merged['name_a_count']).round(2)\n",
    "MUT3_merged['sample'] = 'MUT3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "WT2_jn_count.columns = ['jn_count', 'name_a']\n",
    "WT2_merged = pd.merge(WT2_intron_count_over5, WT2_jn_count, on = 'name_a', how = \"left\")\n",
    "\n",
    "WT2_merged = WT2_merged.fillna(0).round(2)\n",
    "WT2_merged['CoSE'] = (WT2_merged['jn_count']/WT2_merged['name_a_count']).round(2)\n",
    "WT2_merged['sample'] = 'WT2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "WT1_jn_count.columns = ['jn_count', 'name_a']\n",
    "WT1_merged = pd.merge(WT1_intron_count_over5, WT1_jn_count, on = 'name_a', how = \"left\")\n",
    "\n",
    "WT1_merged = WT1_merged.fillna(0).round(2)\n",
    "WT1_merged['CoSE'] = (WT1_merged['jn_count']/WT1_merged['name_a_count']).round(2)\n",
    "WT1_merged['sample'] = 'WT1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "WT_jn_count.columns = ['jn_count', 'name_a']\n",
    "WT_merged = pd.merge(WT_intron_count_over5, WT_jn_count, on = 'name_a', how = \"left\")\n",
    "\n",
    "WT_merged = WT_merged.fillna(0).round(2)\n",
    "WT_merged['CoSE'] = (WT_merged['jn_count']/WT_merged['name_a_count']).round(2)\n",
    "WT_merged['sample'] = 'WT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "MUT_jn_count.columns = ['jn_count', 'name_a']\n",
    "MUT_merged = pd.merge(MUT_intron_count_over5, MUT_jn_count, on = 'name_a', how = \"left\")\n",
    "\n",
    "MUT_merged = MUT_merged.fillna(0).round(2)\n",
    "MUT_merged['CoSE'] = (MUT_merged['jn_count']/MUT_merged['name_a_count']).round(2)\n",
    "MUT_merged['sample'] = 'MUT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "MUT2_merged.to_csv('/home/mp758/scratch60/SF3B1_PRC2_1/SF3B1_LRS/porechop/CoSE/MUT2_first-intron.CoSE.txt',\n",
    "                           sep = '\\t', index = False, header = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "MUT3_merged.to_csv('/home/mp758/scratch60/SF3B1_PRC2_1/SF3B1_LRS/porechop/CoSE/MUT3_first-intron.CoSE.txt',\n",
    "                           sep = '\\t', index = False, header = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "WT1_merged.to_csv('/home/mp758/scratch60/SF3B1_PRC2_1/SF3B1_LRS/porechop/CoSE/WT1_first-intron.CoSE.txt',\n",
    "                           sep = '\\t', index = False, header = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "WT2_merged.to_csv('/home/mp758/scratch60/SF3B1_PRC2_1/SF3B1_LRS/porechop/CoSE/WT2_first-intron.CoSE.txt',\n",
    "                           sep = '\\t', index = False, header = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "WT_merged.to_csv('/home/mp758/scratch60/SF3B1_PRC2_1/SF3B1_LRS/porechop/CoSE/WT_combined_first-intron.CoSE.txt',\n",
    "                           sep = '\\t', index = False, header = True) \n",
    "MUT_merged.to_csv('/home/mp758/scratch60/SF3B1_PRC2_1/SF3B1_LRS/porechop/CoSE/MUT_combined_first-intron.CoSE.txt',\n",
    "                           sep = '\\t', index = False, header = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "WT2_grouped = WT2_TES.groupby(['strand', 'position']).agg({'count':'sum'}) # group by position and strand, sum all counts\n",
    "\n",
    "tmp = WT2_grouped.unstack(level='strand') # separate plus and minus strand counts\n",
    "\n",
    "tmp_plus = tmp['count', '+'].to_frame() # convert both + and - strand series to dataframes\n",
    "tmp_minus = tmp['count', '-'].to_frame()\n",
    "tmp_minus = tmp_minus[::-1] # reverse order of the entries in the minus strand df\n",
    "\n",
    "tmp_minus['new_position'] = list(range(1,1101,1)) # reset the position to be 1-50 for the minus strand so it matches plus strand (flipped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "    WT2_coverage = pd.merge(tmp_plus, tmp_minus, left_index = True, right_on = 'new_position')\n",
    "\n",
    "    WT2_coverage['total_count'] = WT2_coverage['count', '+'] + WT2_coverage['count', '-']\n",
    "    WT2_coverage = WT2_coverage[['new_position', 'total_count']] # drop separate count columns for each strand\n",
    "    WT2_coverage['rel_position'] = range(-100,1000,1) # add relative position around TES\n",
    "    \n",
    "\n",
    "    TES_val = WT2_coverage['total_count'].values[1] # get the coverage at the TES nucleotide position\n",
    "    WT2_coverage['TES_pos_count'] = TES_val\n",
    "    WT2_coverage['normalized_count'] = WT2_coverage['total_count'] / WT2_coverage['TES_pos_count'] # normalize coverage to TES coverage\n",
    "    WT2_coverage['sample'] = \"WT2\" # add sample identifier\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "MUT1_TES = pd.read_csv(\"/home/mp758/scratch60/SF3B1_PRC2_1/SF3B1_LRS/porechop/MUT1/MUT1_cov.txt.gz\",\n",
    "                     compression = 'gzip', sep = '\\t',\n",
    "                     names = ['chr', 'start', 'end', 'name', 'score', 'strand', 'position', 'count'])\n",
    "\n",
    "MUT2_TES = pd.read_csv(\"/home/mp758/scratch60/SF3B1_PRC2_1/SF3B1_LRS/porechop/MUT2/MUT2_cov.txt.gz\",\n",
    "                     compression = 'gzip', sep = '\\t',\n",
    "                     names = ['chr', 'start', 'end', 'name', 'score', 'strand', 'position', 'count'])\n",
    "MUT3_TES = pd.read_csv(\"/home/mp758/scratch60/SF3B1_PRC2_1/April_2022/MUT3/MUT3_cov.txt.gz\",\n",
    "                     compression = 'gzip', sep = '\\t',\n",
    "                     names = ['chr', 'start', 'end', 'name', 'score', 'strand', 'position', 'count'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "MUT_grouped = MUT_TES.groupby(['strand', 'position']).agg({'count':'sum'}) # group by position and strand, sum all counts\n",
    "\n",
    "tmp = MUT_grouped.unstack(level='strand') # separate plus and minus strand counts\n",
    "\n",
    "tmp_plus = tmp['count', '+'].to_frame() # convert both + and - strand series to dataframes\n",
    "tmp_minus = tmp['count', '-'].to_frame()\n",
    "tmp_minus = tmp_minus[::-1] # reverse order of the entries in the minus strand df\n",
    "\n",
    "tmp_minus['new_position'] = list(range(1,1101,1)) # reset the position to be 1-50 for the minus strand so it matches plus strand (flipped)\n",
    "\n",
    "MUT_coverage = pd.merge(tmp_plus, tmp_minus, left_index = True, right_on = 'new_position')\n",
    "\n",
    "MUT_coverage['total_count'] = MUT_coverage['count', '+'] + MUT_coverage['count', '-']\n",
    "MUT_coverage = MUT_coverage[['new_position', 'total_count']] # drop separate count columns for each strand\n",
    "MUT_coverage['rel_position'] = range(-100,1000,1) # add relative position around TES\n",
    "    \n",
    "\n",
    "TES_val = MUT_coverage['total_count'].values[1] # get the coverage at the TES nucleotide position\n",
    "MUT_coverage['TES_pos_count'] = TES_val\n",
    "MUT_coverage['normalized_count'] = MUT_coverage['total_count'] / MUT_coverage['TES_pos_count'] # normalize coverage to TES coverage\n",
    "MUT_coverage['sample'] = \"MUT\" # add sample identifier\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "MUT2_grouped = MUT2_TES.groupby(['strand', 'position']).agg({'count':'sum'}) # group by position and strand, sum all counts\n",
    "\n",
    "tmp = MUT2_grouped.unstack(level='strand') # separate plus and minus strand counts\n",
    "\n",
    "tmp_plus = tmp['count', '+'].to_frame() # convert both + and - strand series to dataframes\n",
    "tmp_minus = tmp['count', '-'].to_frame()\n",
    "tmp_minus = tmp_minus[::-1] # reverse order of the entries in the minus strand df\n",
    "\n",
    "tmp_minus['new_position'] = list(range(1,1101,1)) # reset the position to be 1-50 for the minus strand so it matches plus strand (flipped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "    MUT2_coverage = pd.merge(tmp_plus, tmp_minus, left_index = True, right_on = 'new_position')\n",
    "\n",
    "    MUT2_coverage['total_count'] = MUT2_coverage['count', '+'] + MUT2_coverage['count', '-']\n",
    "    MUT2_coverage = MUT2_coverage[['new_position', 'total_count']] # drop separate count columns for each strand\n",
    "    MUT2_coverage['rel_position'] = range(-100,1000,1) # add relative position around TES\n",
    "    \n",
    "\n",
    "    TES_val = MUT2_coverage['total_count'].values[1] # get the coverage at the TES nucleotide position\n",
    "    MUT2_coverage['TES_pos_count'] = TES_val\n",
    "    MUT2_coverage['normalized_count'] = MUT2_coverage['total_count'] / MUT2_coverage['TES_pos_count'] # normalize coverage to TES coverage\n",
    "    MUT2_coverage['sample'] = \"MUT2\" # add sample identifier\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "MUT1_grouped = MUT1_TES.groupby(['strand', 'position']).agg({'count':'sum'}) # group by position and strand, sum all counts\n",
    "\n",
    "tmp = MUT1_grouped.unstack(level='strand') # separate plus and minus strand counts\n",
    "\n",
    "tmp_plus = tmp['count', '+'].to_frame() # convert both + and - strand series to dataframes\n",
    "tmp_minus = tmp['count', '-'].to_frame()\n",
    "tmp_minus = tmp_minus[::-1] # reverse order of the entries in the minus strand df\n",
    "\n",
    "tmp_minus['new_position'] = list(range(1,1101,1)) # reset the position to be 1-50 for the minus strand so it matches plus strand (flipped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "    MUT1_coverage = pd.merge(tmp_plus, tmp_minus, left_index = True, right_on = 'new_position')\n",
    "\n",
    "    MUT1_coverage['total_count'] = MUT1_coverage['count', '+'] + MUT1_coverage['count', '-']\n",
    "    MUT1_coverage = MUT1_coverage[['new_position', 'total_count']] # drop separate count columns for each strand\n",
    "    MUT1_coverage['rel_position'] = range(-100,1000,1) # add relative position around TES\n",
    "    \n",
    "\n",
    "    TES_val = MUT1_coverage['total_count'].values[1] # get the coverage at the TES nucleotide position\n",
    "    MUT1_coverage['TES_pos_count'] = TES_val\n",
    "    MUT1_coverage['normalized_count'] = MUT1_coverage['total_count'] / MUT1_coverage['TES_pos_count'] # normalize coverage to TES coverage\n",
    "    MUT1_coverage['sample'] = \"MUT1\" # add sample identifier\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "MUT3_grouped = MUT3_TES.groupby(['strand', 'position']).agg({'count':'sum'}) # group by position and strand, sum all counts\n",
    "\n",
    "tmp = MUT3_grouped.unstack(level='strand') # separate plus and minus strand counts\n",
    "\n",
    "tmp_plus = tmp['count', '+'].to_frame() # convert both + and - strand series to dataframes\n",
    "tmp_minus = tmp['count', '-'].to_frame()\n",
    "tmp_minus = tmp_minus[::-1] # reverse order of the entries in the minus strand df\n",
    "\n",
    "tmp_minus['new_position'] = list(range(1,1101,1)) # reset the position to be 1-50 for the minus strand so it matches plus strand (flipped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "    MUT3_coverage = pd.merge(tmp_plus, tmp_minus, left_index = True, right_on = 'new_position')\n",
    "\n",
    "    MUT3_coverage['total_count'] = MUT3_coverage['count', '+'] + MUT3_coverage['count', '-']\n",
    "    MUT3_coverage = MUT3_coverage[['new_position', 'total_count']] # drop separate count columns for each strand\n",
    "    MUT3_coverage['rel_position'] = range(-100,1000,1) # add relative position around TES\n",
    "    \n",
    "\n",
    "    TES_val = MUT3_coverage['total_count'].values[1] # get the coverage at the TES nucleotide position\n",
    "    MUT3_coverage['TES_pos_count'] = TES_val\n",
    "    MUT3_coverage['normalized_count'] = MUT3_coverage['total_count'] / MUT3_coverage['TES_pos_count'] # normalize coverage to TES coverage\n",
    "    MUT3_coverage['sample'] = \"MUT3\" # add sample identifier\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "Coverage_WT1_2_MUT1_2_3= pd.concat([WT1_coverage, WT2_coverage, MUT1_coverage, MUT2_coverage, MUT3_coverage])\n",
    "Coverage_WT1_2_MUT1_2_3.to_csv('/home/mp758/scratch60/SF3B1_PRC2_1/SF3B1_LRS/data/Coverage_WT1_2_MUT1_2_3.txt',\n",
    "                       sep = '\\t', index = False, header = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
